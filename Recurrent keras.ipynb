{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 5.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 670 (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, SimpleRNN, Activation, Masking\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "  'good_for_lunch', \n",
    "  'good_for_dinner', \n",
    "  'takes_reservations', \n",
    "  'outdoor_seating',\n",
    "  'restaurant_is_expensive',\n",
    "  'has_alcohol',\n",
    "  'has_table_service',\n",
    "  'ambience_is_classy',\n",
    "  'good_for_kids'\n",
    "]\n",
    "\n",
    "vgg_cols = ['f' + str(i) for i in range(4096)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(ytrue, ypred):\n",
    "  return K.sum( (ytrue - ypred) ** 2 ) / ytrue.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1596 400 198809 35736\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_hdf('data/Xtrain_full_dataframe.ndf5', 'Xtrain')\n",
    "# cases = data.business_id.unique()\n",
    "# train_cases, val_cases = cases[:-400], cases[-400:]\n",
    "# data_train = data[data.business_id.map(lambda v: v in train_cases)]\n",
    "# data_val = data[data.business_id.map(lambda v: v in val_cases)]\n",
    "\n",
    "# print len(data_train), len(data_val), len(data_train) + len(data_val), len(data)\n",
    "\n",
    "data_train = pd.read_hdf('data/Dataframe_train1596.h5', 'Xtrain')\n",
    "data_val = pd.read_hdf('data/Dataframe_val400.h5', 'Xval')\n",
    "train_cases = data_train.business_id.unique()\n",
    "val_cases = data_val.business_id.unique()\n",
    "num_train, num_val = len(train_cases), len(val_cases)\n",
    "\n",
    "print len(train_cases), len(val_cases), len(data_train), len(data_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / val generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def train_generator(n_batches, maxlen, dimin, dimout):\n",
    "  while True:\n",
    "    shuffled = train_cases.copy()\n",
    "    np.random.shuffle(shuffled)\n",
    "    \n",
    "    batches = np.array_split(shuffled, n_batches)\n",
    "    \n",
    "    for batch in batches:\n",
    "      X = np.zeros((len(batch), maxlen, dimin)) - 1\n",
    "      Y = np.zeros((len(batch), dimout))\n",
    "      \n",
    "      for idx, case in enumerate(batch):\n",
    "        res = data_train[data_train.business_id == case]\n",
    "        if len(res) > maxlen:\n",
    "          res = res.sample(maxlen)\n",
    "        else:\n",
    "          res = res.sample(len(res))\n",
    "        X[idx, :len(res), :] = np.array(res[vgg_cols])\n",
    "        Y[idx] = np.array(res[categories][:1])\n",
    "      yield (X, Y)\n",
    "\n",
    "\n",
    "def val_generator(n_batches, maxlen, dimin, dimout):\n",
    "  while True:\n",
    "    batches = np.array_split(val_cases, n_batches)\n",
    "    \n",
    "    for batch in batches:\n",
    "      X = np.zeros((len(batch), maxlen, dimin)) - 1\n",
    "      Y = np.zeros((len(batch), dimout))\n",
    "      \n",
    "      for idx, case in enumerate(batch):\n",
    "        res = data_val[data_val.business_id == case][:maxlen]\n",
    "        X[idx, :len(res), :] = np.array(res[vgg_cols])\n",
    "        Y[idx] = np.array(res[categories][:1])\n",
    "      yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def train_generator_chunked(n_batches, maxlen, dimin, dimout):\n",
    "  while True:\n",
    "    shuffled = train_cases.copy()\n",
    "    np.random.shuffle(shuffled)\n",
    "    \n",
    "    batches = np.array_split(shuffled, n_batches)\n",
    "    \n",
    "    for batch in batches:\n",
    "      X = np.zeros((len(batch), maxlen, dimin)) - 1\n",
    "      Y = np.zeros((len(batch), dimout))\n",
    "      \n",
    "      for idx, case in enumerate(batch):\n",
    "        res = data_train[data_train.business_id == case]\n",
    "        \n",
    "        # set Y, it is easy\n",
    "        Y[idx] = np.array(res[categories][:1])\n",
    "        \n",
    "        # set X if there are fewer rows than required\n",
    "#         res = res.sample(len(res)) # shuffle rows\n",
    "        res = np.array(res[vgg_cols])\n",
    "        \n",
    "        if len(res) < maxlen:\n",
    "          X[idx, :len(res)] = res\n",
    "        else:\n",
    "          i = 0\n",
    "          for c in np.array_split(res, maxlen):\n",
    "            X[idx, i] = c.mean(axis=0)\n",
    "            i += 1\n",
    "\n",
    "      yield (X, Y)\n",
    "\n",
    "\n",
    "def val_generator_chunked(n_batches, maxlen, dimin, dimout):\n",
    "  while True:\n",
    "    batches = np.array_split(val_cases, n_batches)\n",
    "    \n",
    "    for batch in batches:\n",
    "      X = np.zeros((len(batch), maxlen, dimin)) - 1\n",
    "      Y = np.zeros((len(batch), dimout))\n",
    "      \n",
    "      for idx, case in enumerate(batch):\n",
    "        res = data_val[data_val.business_id == case]\n",
    "        \n",
    "        # set Y, it is easy\n",
    "        Y[idx] = np.array(res[categories][:1])\n",
    "        \n",
    "        # set X if there are fewer rows than required\n",
    "        res = np.array(res[vgg_cols])\n",
    "        \n",
    "        if len(res) < maxlen:\n",
    "          X[idx, :len(res)] = res\n",
    "        else:\n",
    "          i = 0\n",
    "          for c in np.array_split(res, maxlen):\n",
    "            X[idx, i] = c.mean(axis=0)\n",
    "            i += 1\n",
    "\n",
    "      yield (X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 10\n",
    "dimin  = 4096\n",
    "dimout = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define custom callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class f1printerCallback(Callback):\n",
    "  def __init__(self):\n",
    "    self.bestf1val = 0\n",
    "  \n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.epochs = []\n",
    "    self.history = {'train': [], 'val': []}\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "#     tgen = train_generator(1, maxlen, dimin, dimout)\n",
    "#     x, train_true = next(tgen)\n",
    "#     train_pred = self.model.predict(x)\n",
    "    \n",
    "#     vgen = val_generator(1, maxlen, dimin, dimout)\n",
    "    vgen = val_generator_chunked(1, maxlen, dimin, dimout)\n",
    "    x, val_true = next(vgen)\n",
    "    val_pred = self.model.predict(x)\n",
    "      \n",
    "#     train_pred[train_pred >= .5] = 1\n",
    "#     train_pred[train_pred < .5] = 0\n",
    "#     trainf1 = f1_score(train_true, train_pred, average='micro')\n",
    "    \n",
    "    val_pred[val_pred >= .5] = 1\n",
    "    val_pred[val_pred < .5] = 0\n",
    "    valf1 = f1_score(val_true, val_pred, average='micro')\n",
    "    \n",
    "    print ' - val F1: %f' % valf1\n",
    "#     print 'F1: %f (train), %f (val)' % (trainf1, valf1)\n",
    "\n",
    "    if valf1 > self.bestf1val:\n",
    "      print 'F1 val score improved! From %f to %f. Saving model...' % (self.bestf1val, valf1)\n",
    "      self.bestf1val = valf1\n",
    "      self.model.save_weights('models/lstm_basic.h5', overwrite=True)\n",
    "    \n",
    "    self.epochs.append(epoch)\n",
    "#     self.history['train'].append(trainf1)\n",
    "    self.history['val'].append(valf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cb = f1printerCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(-1, input_shape=(maxlen, dimin)))\n",
    "# model.add(LSTM(\n",
    "#     100, \n",
    "#     input_dim=dimin, \n",
    "#     input_length=maxlen, \n",
    "# #     W_regularizer=l2(), \n",
    "# #     U_regularizer=l2(), \n",
    "#     dropout_W=0.5, \n",
    "#     dropout_U=0.5,\n",
    "#     return_sequences=True\n",
    "# ))\n",
    "model.add(SimpleRNN(\n",
    "    100, \n",
    "    input_dim=dimin, \n",
    "    input_length=maxlen, \n",
    "    dropout_W=0.5, \n",
    "    dropout_U=0.5,\n",
    "))\n",
    "# model.add(Dense(100, activation='relu', W_regularizer=l2()))\n",
    "model.add(Dense(9, activation='sigmoid', W_regularizer=l2()))\n",
    "# model.add(Dense(9, activation='sigmoid'))\n",
    "# model.compile(loss=loss, optimizer=Adam(lr=0.0003))\n",
    "model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.9597 - val F1: 0.693953\n",
      "F1 val score improved! From 0.000000 to 0.693953. Saving model...\n",
      "1596/1596 [==============================] - 14s - loss: 1.9537 - val_loss: 1.6124\n",
      "Epoch 2/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.5405 - val F1: 0.713481\n",
      "F1 val score improved! From 0.693953 to 0.713481. Saving model...\n",
      "1596/1596 [==============================] - 12s - loss: 1.5423 - val_loss: 1.5665\n",
      "Epoch 3/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.4287 - val F1: 0.704474\n",
      "1596/1596 [==============================] - 12s - loss: 1.4259 - val_loss: 1.5150\n",
      "Epoch 4/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.3800 - val F1: 0.734830\n",
      "F1 val score improved! From 0.713481 to 0.734830. Saving model...\n",
      "1596/1596 [==============================] - 12s - loss: 1.3831 - val_loss: 1.4654\n",
      "Epoch 5/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.3284 - val F1: 0.738323\n",
      "F1 val score improved! From 0.734830 to 0.738323. Saving model...\n",
      "1596/1596 [==============================] - 12s - loss: 1.3237 - val_loss: 1.4467\n",
      "Epoch 6/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.2923 - val F1: 0.739625\n",
      "F1 val score improved! From 0.738323 to 0.739625. Saving model...\n",
      "1596/1596 [==============================] - 12s - loss: 1.2914 - val_loss: 1.4063\n",
      "Epoch 7/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.2519 - val F1: 0.744271\n",
      "F1 val score improved! From 0.739625 to 0.744271. Saving model...\n",
      "1596/1596 [==============================] - 12s - loss: 1.2488 - val_loss: 1.4092\n",
      "Epoch 8/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.2306 - val F1: 0.731209\n",
      "1596/1596 [==============================] - 12s - loss: 1.2312 - val_loss: 1.4113\n",
      "Epoch 9/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.1816 - val F1: 0.738896\n",
      "1596/1596 [==============================] - 12s - loss: 1.1817 - val_loss: 1.4240\n",
      "Epoch 10/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.1827 - val F1: 0.754660\n",
      "F1 val score improved! From 0.744271 to 0.754660. Saving model...\n",
      "1596/1596 [==============================] - 12s - loss: 1.1851 - val_loss: 1.3820\n",
      "Epoch 11/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.1421 - val F1: 0.747996\n",
      "1596/1596 [==============================] - 12s - loss: 1.1449 - val_loss: 1.4123\n",
      "Epoch 12/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.1230 - val F1: 0.733523\n",
      "1596/1596 [==============================] - 12s - loss: 1.1257 - val_loss: 1.3798\n",
      "Epoch 13/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.1144 - val F1: 0.739855\n",
      "1596/1596 [==============================] - 12s - loss: 1.1159 - val_loss: 1.3574\n",
      "Epoch 14/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.1016 - val F1: 0.732786\n",
      "1596/1596 [==============================] - 12s - loss: 1.1060 - val_loss: 1.3973\n",
      "Epoch 15/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.1003 - val F1: 0.742142\n",
      "1596/1596 [==============================] - 12s - loss: 1.1028 - val_loss: 1.3931\n",
      "Epoch 16/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.1004 - val F1: 0.740923\n",
      "1596/1596 [==============================] - 12s - loss: 1.0984 - val_loss: 1.4011\n",
      "Epoch 17/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.0626 - val F1: 0.746250\n",
      "1596/1596 [==============================] - 12s - loss: 1.0625 - val_loss: 1.3616\n",
      "Epoch 18/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.0225 - val F1: 0.750845\n",
      "1596/1596 [==============================] - 12s - loss: 1.0242 - val_loss: 1.3586\n",
      "Epoch 19/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.0247 - val F1: 0.757895\n",
      "F1 val score improved! From 0.754660 to 0.757895. Saving model...\n",
      "1596/1596 [==============================] - 12s - loss: 1.0238 - val_loss: 1.3535\n",
      "Epoch 20/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.0136 - val F1: 0.751291\n",
      "1596/1596 [==============================] - 12s - loss: 1.0116 - val_loss: 1.3719\n",
      "Epoch 21/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.0208 - val F1: 0.753441\n",
      "1596/1596 [==============================] - 12s - loss: 1.0236 - val_loss: 1.3846\n",
      "Epoch 22/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 1.0047 - val F1: 0.738192\n",
      "1596/1596 [==============================] - 12s - loss: 1.0055 - val_loss: 1.3937\n",
      "Epoch 23/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 0.9996 - val F1: 0.754787\n",
      "1596/1596 [==============================] - 12s - loss: 0.9978 - val_loss: 1.3665\n",
      "Epoch 24/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 0.9825 - val F1: 0.748994\n",
      "1596/1596 [==============================] - 12s - loss: 0.9801 - val_loss: 1.3639\n",
      "Epoch 25/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 0.9766 - val F1: 0.752856\n",
      "1596/1596 [==============================] - 12s - loss: 0.9761 - val_loss: 1.3708\n",
      "Epoch 26/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 0.9831 - val F1: 0.750453\n",
      "1596/1596 [==============================] - 12s - loss: 0.9840 - val_loss: 1.3873\n",
      "Epoch 27/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 0.9630 - val F1: 0.749392\n",
      "1596/1596 [==============================] - 12s - loss: 0.9650 - val_loss: 1.3838\n",
      "Epoch 28/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 0.9531 - val F1: 0.747084\n",
      "1596/1596 [==============================] - 12s - loss: 0.9545 - val_loss: 1.3702\n",
      "Epoch 29/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 0.9280 - val F1: 0.756207\n",
      "1596/1596 [==============================] - 12s - loss: 0.9256 - val_loss: 1.3855\n",
      "Epoch 30/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 0.9270 - val F1: 0.746885\n",
      "1596/1596 [==============================] - 12s - loss: 0.9318 - val_loss: 1.3959\n",
      "Epoch 31/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 0.9499 - val F1: 0.749235\n",
      "1596/1596 [==============================] - 12s - loss: 0.9506 - val_loss: 1.3613\n",
      "Epoch 32/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 0.9156 - val F1: 0.753207\n",
      "1596/1596 [==============================] - 12s - loss: 0.9178 - val_loss: 1.3699\n",
      "Epoch 33/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 0.9252 - val F1: 0.738794\n",
      "1596/1596 [==============================] - 12s - loss: 0.9236 - val_loss: 1.4156\n",
      "Epoch 34/100\n",
      "1557/1596 [============================>.] - ETA: 0s - loss: 0.9167"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-3e237f72478a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0mnb_val_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;32m/home/budmitr/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, show_accuracy, callbacks, validation_data, nb_val_samples, class_weight, nb_worker, nb_val_worker)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                                            \u001b[0mshow_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_accuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                                            \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_val_worker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                                            wait_time=wait_time)\n\u001b[0m\u001b[0;32m   1170\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m                         val_outs = self.evaluate(X_val, y_val,\n",
      "\u001b[1;32m/home/budmitr/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, val_samples, show_accuracy, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mdone_samples\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 974\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_generator_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    975\u001b[0m             \u001b[0mdo_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             outs = self.evaluate(X, y, batch_size=do_samples,\n",
      "\u001b[1;32m/home/budmitr/anaconda/lib/python2.7/Queue.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/budmitr/anaconda/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.wait(): got it\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(\n",
    "  # generator=train_generator(50, maxlen, dimin, dimout), \n",
    "  generator=train_generator_chunked(40, maxlen, dimin, dimout), \n",
    "  samples_per_epoch=num_train,\n",
    "  validation_data=val_generator_chunked(5, maxlen, dimin, dimout),\n",
    "  nb_val_samples=num_val,\n",
    "  nb_epoch=100,\n",
    "  callbacks=[cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
