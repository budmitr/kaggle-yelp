{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 670 (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.layers import LeakyReLU, PReLU, ELU, ParametricSoftplus, ThresholdedLinear, ThresholdedReLU, SReLU\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization, Dropout\n",
    "from keras.regularizers import l1, l2, l1l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 5.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "  'good_for_lunch', \n",
    "  'good_for_dinner', \n",
    "  'takes_reservations', \n",
    "  'outdoor_seating',\n",
    "  'restaurant_is_expensive',\n",
    "  'has_alcohol',\n",
    "  'has_table_service',\n",
    "  'ambience_is_classy',\n",
    "  'good_for_kids'\n",
    "]\n",
    "\n",
    "vgg_cols = ['f' + str(i) for i in range(4096)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1596, 4096) (400, 4096) (1596, 9) (400, 9)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_hdf('data/Xtrain_grouped.hdf5')\n",
    "X, Y = np.array(data[vgg_cols]), np.array(data[categories])\n",
    "\n",
    "random_state = np.random.RandomState(0)\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, Y, test_size=.2, random_state=random_state)\n",
    "valset = (Xval, yval)\n",
    "\n",
    "print Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(ytrue, ypred):\n",
    "  return K.sum( (ytrue - ypred) ** 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class f1printerCallback(Callback):\n",
    "  def __init__(self, savefile=None):\n",
    "    self.bestf1train = 0\n",
    "    self.bestf1val = 0\n",
    "    self.bestmulti = 0\n",
    "    \n",
    "    self.savefile = savefile\n",
    "  \n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.epochs = []\n",
    "    self.history = {'trainf1': [], 'valf1': []}\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    pred = self.model.predict(Xtrain)\n",
    "    pred[pred < .5] = 0\n",
    "    pred[pred > .5] = 1\n",
    "    f1_train = f1_score(ytrain, pred, average='micro')\n",
    "    \n",
    "    pred = self.model.predict(Xval)\n",
    "    pred[pred < .5] = 0\n",
    "    pred[pred > .5] = 1\n",
    "    f1_val = f1_score(yval, pred, average='micro')\n",
    "\n",
    "    multi = f1_train * f1_val\n",
    "    if f1_val > self.bestf1val:\n",
    "#     if f1_train > self.bestf1train:\n",
    "#     if multi > self.bestmulti:\n",
    "      print 'Epoch %d -- train %f, val %f, multi %f' % (epoch, f1_train, f1_val, multi)\n",
    "      self.bestmulti = multi\n",
    "      self.bestf1val = f1_val\n",
    "      \n",
    "      if f1_val > 0.84 and self.savefile:\n",
    "        print 'Saving weights...'\n",
    "        self.model.save_weights(self.savefile, overwrite=True)\n",
    "    \n",
    "    self.epochs.append(epoch)\n",
    "    self.history['trainf1'].append(f1_train)\n",
    "    self.history['valf1'].append(f1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1: This configurations is currently the best one\n",
    "\n",
    "Epoch 253 -- train 0.961918, val 0.844794, multi 0.812623\n",
    "\n",
    "0.80999 Kaggle LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# np.random.seed(0)\n",
    "\n",
    "# activation = 'softplus'\n",
    "# dropout_val = .5\n",
    "# n_neurons = 100\n",
    "\n",
    "# model.add(Dense(n_neurons, input_shape=(4096,), activation=activation))\n",
    "# model.add(Dropout(dropout_val))\n",
    "\n",
    "# model.add(Dense(9))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model2\n",
    "\n",
    "Epoch 107 -- train 0.942859, val 0.846003, multi 0.797662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# np.random.seed(0)\n",
    "\n",
    "# activation = 'softplus'\n",
    "# dropout_val = .35\n",
    "# n_neurons = 200\n",
    "\n",
    "# model.add(Dense(n_neurons, input_shape=(4096,), activation=activation))\n",
    "# model.add(Dropout(dropout_val))\n",
    "\n",
    "# model.add(Dense(n_neurons, activation=activation))\n",
    "# model.add(Dropout(dropout_val))\n",
    "\n",
    "# model.add(Dense(9))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model3\n",
    "\n",
    "Epoch 227 -- train 0.935710, val 0.846756, multi 0.792318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# np.random.seed(0)\n",
    "\n",
    "# activation = 'softplus'\n",
    "# dropout_val = .4\n",
    "# n_neurons = 100\n",
    "\n",
    "# model.add(Dense(n_neurons, input_shape=(4096,), activation=activation))\n",
    "# model.add(Dropout(dropout_val))\n",
    "\n",
    "# model.add(Dense(n_neurons, activation=activation))\n",
    "# model.add(Dropout(dropout_val))\n",
    "\n",
    "# model.add(Dense(n_neurons, activation=activation))\n",
    "# model.add(Dropout(dropout_val))\n",
    "\n",
    "# model.add(Dense(9))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model4\n",
    "\n",
    "Epoch 138 -- train 0.947807, val 0.847851, multi 0.803599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# np.random.seed(0)\n",
    "\n",
    "# activation = 'softplus'\n",
    "# dropout_val = .35\n",
    "# n_neurons = 200\n",
    "\n",
    "# model.add(Dense(n_neurons, input_shape=(4096,), activation=activation))\n",
    "# model.add(Dropout(dropout_val))\n",
    "\n",
    "# model.add(Dense(n_neurons, activation=activation))\n",
    "# model.add(Dropout(dropout_val))\n",
    "\n",
    "# model.add(Dense(n_neurons, activation=activation))\n",
    "# model.add(Dropout(dropout_val))\n",
    "\n",
    "# model.add(Dense(9))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model5\n",
    "\n",
    "Epoch 125 -- train 0.949649, val 0.848280, multi 0.805568\n",
    "\n",
    "LB 0.80318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# np.random.seed(0)\n",
    "\n",
    "# dropout_val = .4\n",
    "# n_neurons = 300\n",
    "# activation = SReLU\n",
    "\n",
    "# model.add(Dense(n_neurons, input_shape=(4096,)))\n",
    "# model.add(activation())\n",
    "# model.add(Dropout(dropout_val))\n",
    "\n",
    "# model.add(Dense(n_neurons))\n",
    "# model.add(activation())\n",
    "# model.add(Dropout(dropout_val))\n",
    "\n",
    "# model.add(Dense(n_neurons))\n",
    "# model.add(activation())\n",
    "# model.add(Dropout(dropout_val))\n",
    "\n",
    "# model.add(Dense(9))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain best models and save their weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.844793713163\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "np.random.seed(0)\n",
    "model1.add(Dense(100, input_shape=(4096,), activation='softplus'))\n",
    "model1.add(Dropout(.5))\n",
    "model1.add(Dense(9))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.compile(loss=loss, optimizer='adam')\n",
    "\n",
    "hist = model1.fit(Xtrain, ytrain, verbose=0, nb_epoch=254)\n",
    "\n",
    "pred = model1.predict(Xval)\n",
    "pred[pred < .5] = 0\n",
    "pred[pred > .5] = 1\n",
    "f1_val = f1_score(yval, pred, average='micro')\n",
    "print\n",
    "print f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.846002805049\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "np.random.seed(0)\n",
    "model2.add(Dense(200, input_shape=(4096,), activation='softplus'))\n",
    "model2.add(Dropout(.35))\n",
    "model2.add(Dense(200, activation='softplus'))\n",
    "model2.add(Dropout(.35))\n",
    "model2.add(Dense(9))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.compile(loss=loss, optimizer='adam')\n",
    "\n",
    "hist = model2.fit(Xtrain, ytrain, verbose=0, nb_epoch=108)\n",
    "\n",
    "pred = model2.predict(Xval)\n",
    "pred[pred < .5] = 0\n",
    "pred[pred > .5] = 1\n",
    "f1_val = f1_score(yval, pred, average='micro')\n",
    "print\n",
    "print f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.846756152125\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "np.random.seed(0)\n",
    "model3.add(Dense(100, input_shape=(4096,), activation='softplus'))\n",
    "model3.add(Dropout(.4))\n",
    "model3.add(Dense(100, activation='softplus'))\n",
    "model3.add(Dropout(.4))\n",
    "model3.add(Dense(100, activation='softplus'))\n",
    "model3.add(Dropout(.4))\n",
    "model3.add(Dense(9))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.compile(loss=loss, optimizer='adam')\n",
    "\n",
    "hist = model3.fit(Xtrain, ytrain, verbose=0, nb_epoch=228)\n",
    "\n",
    "pred = model3.predict(Xval)\n",
    "pred[pred < .5] = 0\n",
    "pred[pred > .5] = 1\n",
    "f1_val = f1_score(yval, pred, average='micro')\n",
    "print\n",
    "print f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.847850678733\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "np.random.seed(0)\n",
    "model4.add(Dense(200, input_shape=(4096,), activation='softplus'))\n",
    "model4.add(Dropout(.35))\n",
    "model4.add(Dense(200, activation='softplus'))\n",
    "model4.add(Dropout(.35))\n",
    "model4.add(Dense(200, activation='softplus'))\n",
    "model4.add(Dropout(.35))\n",
    "model4.add(Dense(9))\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.compile(loss=loss, optimizer='adam')\n",
    "\n",
    "hist = model4.fit(Xtrain, ytrain, verbose=0, nb_epoch=139)\n",
    "\n",
    "pred = model4.predict(Xval)\n",
    "pred[pred < .5] = 0\n",
    "pred[pred > .5] = 1\n",
    "f1_val = f1_score(yval, pred, average='micro')\n",
    "print\n",
    "print f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.848279751833\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "np.random.seed(0)\n",
    "model5.add(Dense(300, input_shape=(4096,)))\n",
    "model5.add(SReLU())\n",
    "model5.add(Dropout(.4))\n",
    "model5.add(Dense(300))\n",
    "model5.add(SReLU())\n",
    "model5.add(Dropout(.4))\n",
    "model5.add(Dense(300))\n",
    "model5.add(SReLU())\n",
    "model5.add(Dropout(.4))\n",
    "model5.add(Dense(9))\n",
    "model5.add(Activation('sigmoid'))\n",
    "model5.compile(loss=loss, optimizer='adam')\n",
    "\n",
    "hist = model5.fit(Xtrain, ytrain, verbose=0, nb_epoch=126)\n",
    "\n",
    "pred = model5.predict(Xval)\n",
    "pred[pred < .5] = 0\n",
    "pred[pred > .5] = 1\n",
    "f1_val = f1_score(yval, pred, average='micro')\n",
    "print\n",
    "print f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build an ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try on val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83150126671899394"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [model1, model2, model3, model4, model5]\n",
    "ensemble_pred = np.zeros((5, Xval.shape[0], 9))\n",
    "\n",
    "for i, m in enumerate(models):\n",
    "  pred = m.predict(Xval)\n",
    "  ensemble_pred[i] = pred\n",
    "\n",
    "pred_mean = ensemble_pred.mean(axis=0)\n",
    "pred_mean[pred_mean < .5] = 0\n",
    "pred_mean[pred_mean > .5] = 1\n",
    "pred_mean.shape\n",
    "\n",
    "f1_score(yval, pred_mean, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try on test data\n",
    "\n",
    "KAGGLE LB 0.81371!!! 14th place atm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9)\n"
     ]
    }
   ],
   "source": [
    "models = [model1, model2, model3, model4, model5]\n",
    "ensemble_pred = np.zeros((5, Xtest.shape[0], 9))\n",
    "\n",
    "for i, m in enumerate(models):\n",
    "  pred = m.predict(Xtest)\n",
    "  ensemble_pred[i] = pred\n",
    "\n",
    "pred = ensemble_pred.mean(axis=0)\n",
    "pred[pred < .5] = 0\n",
    "pred[pred > .5] = 1\n",
    "print pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -- train 0.757415, val 0.736081, multi 0.557519\n",
      "Epoch 1 -- train 0.792720, val 0.770306, multi 0.610637\n",
      "Epoch 3 -- train 0.805266, val 0.780460, multi 0.628478\n",
      "Epoch 4 -- train 0.807675, val 0.786365, multi 0.635127\n",
      "Epoch 5 -- train 0.829300, val 0.805268, multi 0.667808\n",
      "Epoch 8 -- train 0.837286, val 0.807596, multi 0.676188\n",
      "Epoch 9 -- train 0.842008, val 0.814174, multi 0.685541\n",
      "Epoch 12 -- train 0.848854, val 0.818757, multi 0.695006\n",
      "Epoch 15 -- train 0.855214, val 0.821956, multi 0.702948\n",
      "Epoch 17 -- train 0.863123, val 0.827352, multi 0.714107\n",
      "Epoch 18 -- train 0.865264, val 0.829116, multi 0.717404\n",
      "Epoch 19 -- train 0.862231, val 0.834113, multi 0.719198\n",
      "Epoch 26 -- train 0.874864, val 0.834335, multi 0.729929\n",
      "Epoch 33 -- train 0.883403, val 0.835813, multi 0.738359\n",
      "Epoch 36 -- train 0.886229, val 0.835982, multi 0.740872\n",
      "Epoch 39 -- train 0.888161, val 0.841870, multi 0.747716\n",
      "Epoch 56 -- train 0.907545, val 0.843534, multi 0.765545\n",
      "Epoch 73 -- train 0.911717, val 0.844804, multi 0.770221\n",
      "Epoch 105 -- train 0.938591, val 0.845264, multi 0.793357\n",
      "Epoch 116 -- train 0.938054, val 0.848080, multi 0.795545\n",
      "Saving weights...\n",
      "Epoch 125 -- train 0.949649, val 0.848280, multi 0.805568\n",
      "Saving weights...\n"
     ]
    }
   ],
   "source": [
    "cb = f1printerCallback()\n",
    "hist = model.fit(Xtrain, ytrain, callbacks=[cb], verbose=0, nb_epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949648543968 0.848279751833\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('models/dummy_dense_average_model.h5')\n",
    "\n",
    "pred = model.predict(Xtrain)\n",
    "pred[pred < .5] = 0\n",
    "pred[pred > .5] = 1\n",
    "\n",
    "f1_train = f1_score(ytrain, pred, average='micro')\n",
    "\n",
    "pred = model.predict(Xval)\n",
    "pred[pred < .5] = 0\n",
    "pred[pred > .5] = 1\n",
    "\n",
    "f1_val = f1_score(yval, pred, average='micro')\n",
    "\n",
    "print f1_train, f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try this little stuff on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1637\n",
      "2 1707\n",
      "3 1654\n",
      "4 1746\n",
      "5 1735\n",
      "6 1521\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([(0,1,2,3,4,5,6,7,8)])\n",
    "\n",
    "dataTest = None\n",
    "for i in range(1, 7):\n",
    "  part = pd.read_hdf('data/Xtest_grouped_part' + str(i) + '.hdf5', 'Xtest')\n",
    "  print i, len(part)\n",
    "  \n",
    "  if dataTest is None:\n",
    "    dataTest = part\n",
    "  else:\n",
    "    dataTest = dataTest.append(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4096)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = np.array(dataTest[vgg_cols])\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(Xtest)\n",
    "pred[pred < .5] = 0\n",
    "pred[pred > .5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = mlb.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_str = [' '.join(map(str, l)) for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003sg</td>\n",
       "      <td>1 2 3 5 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00er5</td>\n",
       "      <td>1 2 3 5 6 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00kad</td>\n",
       "      <td>1 2 3 5 6 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00mc6</td>\n",
       "      <td>1 2 5 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00q7x</td>\n",
       "      <td>1 2 4 5 6 7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  business_id       labels\n",
       "0       003sg    1 2 3 5 6\n",
       "1       00er5  1 2 3 5 6 8\n",
       "2       00kad  1 2 3 5 6 8\n",
       "3       00mc6      1 2 5 6\n",
       "4       00q7x  1 2 4 5 6 7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'business_id': dataTest.index, 'labels': pd.Series(labels_str)})\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv('results/first_ensemble_val_8471.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
